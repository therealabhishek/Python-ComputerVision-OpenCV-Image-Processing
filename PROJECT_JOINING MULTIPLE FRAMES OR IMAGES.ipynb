{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In this project we will be seeing how to join multiple images.\n",
    "\n",
    "Joining images is particularly useful when we have to check the flow of operations perfomed on an image.\n",
    "\n",
    "We will see how image joining is useful in the project below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT FLOW:\n",
    "\n",
    "# importing the required libraries for the project.\n",
    "# performing different operations on the image.\n",
    "# stacking the images to observe the flow of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries:\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without stacking:\n",
    "\n",
    "- Without stacking we can observe that we are not able to see all the operations performed on the image at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required image:\n",
    "\n",
    "image = cv2.imread('images/salah_smiling.jpeg',0)\n",
    "# resizing the image\n",
    "image1 = cv2.resize(image, (0,0), None, 0.7, 0.7)\n",
    "# blurring the image using gaussian blur.\n",
    "imageBlur = cv2.GaussianBlur(image1, (3,3), 0)\n",
    "# detecting the image edges using Canny Edge Detection.\n",
    "imageCanny = cv2.Canny(imageBlur, 30, 250)\n",
    "# Dilating the image whose edges have been detected.\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "imageDilation = cv2.dilate(imageCanny,kernel)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Original_Image\", image1)\n",
    "cv2.imshow(\"Blur_Image\", imageBlur)\n",
    "cv2.imshow(\"Edge_Image\", imageCanny)\n",
    "cv2.imshow(\"Dilated_Image\", imageDilation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with stacking:\n",
    "\n",
    "- with stacking we can see that we are able to see all the operations performed on the image at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required image:\n",
    "\n",
    "image = cv2.imread('images/salah_smiling.jpeg',0)\n",
    "# resizing the image\n",
    "image1 = cv2.resize(image, (0,0), None, 0.5, 0.5)\n",
    "# blurring the image using gaussian blur.\n",
    "imageBlur = cv2.GaussianBlur(image1, (7,7), 0)\n",
    "# detecting the image edges using Canny Edge Detection.\n",
    "imageCanny = cv2.Canny(imageBlur, 30, 250)\n",
    "# Dilating the image whose edges have been detected.\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "imageDilation = cv2.dilate(imageCanny,kernel , iterations = 2)\n",
    "\n",
    "# stacking images horizontally.\n",
    "horizontal_stack1 = np.hstack((image1, imageBlur))\n",
    "horizontal_stack2 = np.hstack((imageCanny, imageDilation))\n",
    "# vertically stacking the frames\n",
    "vertical_stack = np.vstack((horizontal_stack1, horizontal_stack2))\n",
    "\n",
    "\n",
    "# Checking the stacked images.\n",
    "cv2.imshow(\"Stacked Images\", vertical_stack)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performing stacking on video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameWidth = 640\n",
    "frameHeight = 360\n",
    "camera = cv2.VideoCapture(0)\n",
    "camera.set(3, frameWidth)\n",
    "camera.set(4, frameHeight)\n",
    "\n",
    "while True:\n",
    "    ret, image = camera.read()\n",
    "    if ret:\n",
    "        #converting image to grayscale\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        #blurring the image\n",
    "        imageBlur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "        #detecting image edges\n",
    "        imageCanny = cv2.Canny(imageBlur, 30, 250)\n",
    "\n",
    "        # Dilating the image whose edges have been detected.\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        imageDilation = cv2.dilate(imageCanny,kernel , iterations = 2)\n",
    "        \n",
    "        # horizontally stacking the frames\n",
    "        horizontal_stack1 = np.hstack((gray, imageBlur))\n",
    "        horizontal_stack2 = np.hstack((imageCanny, imageDilation))\n",
    "        # vertically stacking the frames\n",
    "        vertical_stack = np.vstack((horizontal_stack1, horizontal_stack2))\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Stacked_Images', vertical_stack)\n",
    "        \n",
    "        \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == ord('q'): # press 'q' to quit\n",
    "        break\n",
    "        \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
